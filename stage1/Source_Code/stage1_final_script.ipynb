{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Dev set: 200\n",
      "Length of Test set:100\n",
      "Dev Set :\n",
      "Length of data with features: 57916\n",
      "Number of names marked up: 3462\n",
      "Test Set :\n",
      "Length of data with features: 26064\n",
      "Number of names marked up: 1567\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python2.7\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "cities = {}\n",
    "Countries = {}\n",
    "def read_cities():\n",
    "    with open('cities.csv') as f:\n",
    "        reader = csv.reader(f)\n",
    "        # skip header\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            cities[row[0].lower()] = 1\n",
    "\n",
    "def read_countries():\n",
    "    with open('Countries.csv') as f:\n",
    "        reader = csv.reader(f)\n",
    "        # skip header\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            Countries[row[0].lower()] = 1\n",
    "            \n",
    "def words_filter(word):\n",
    "    \"\"\"\n",
    "    Function to remove out all empty string.\n",
    "    \"\"\"\n",
    "    if word == '':\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def parse_words(word):\n",
    "    \"\"\"\n",
    "    Function to remove . 's ' from the last parts of the words and \" ( ) ,  from\n",
    "    beginning or last part of the word.\n",
    "    \"\"\"    \n",
    "    word = word.strip('\\\"').rstrip('.').rstrip('\\'').strip(',').strip('(')\\\n",
    "                                                               .strip(')')\\\n",
    "                                                               .strip('?')\\\n",
    "                                                               .strip(':')\n",
    "    if word.endswith('\\'s'):\n",
    "        word = word.rstrip('\\'s')\n",
    "    return word\n",
    "\n",
    "def filter_training_set(string):\n",
    "    \"\"\"\n",
    "    Function to remove out too many negatives from training set. The current\n",
    "    filter accepts elements into training set only if at least one of the\n",
    "    elements is capitalized.\n",
    "    \"\"\"\n",
    "    for word in string.split(\" \"):\n",
    "        if word == '':\n",
    "            return False\n",
    "        if word[0].isupper():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def label(string, names):\n",
    "    \"\"\"\n",
    "    Just return positive or negative label.\n",
    "    \"\"\"\n",
    "    if string in names:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def feature_is_all_capitals(string):\n",
    "    \"\"\"\n",
    "    If all the words in the string are capitalized, return True.\n",
    "    \"\"\"\n",
    "    words = string.split(\" \")\n",
    "    for word in words:\n",
    "        if word == '' or word[0].islower():\n",
    "            return 0\n",
    "    return 1\n",
    "\n",
    "def feature_possessive_form(string, content):\n",
    "    \"\"\"\n",
    "    If the last word in the string end's with 's or ', return True.\n",
    "    \"\"\"\n",
    "    last_word = string.strip(\" \").split(\" \")[-1]\n",
    "    assert(last_word)\n",
    "    match_obj = re.search(last_word + r\"\\'s?\", content)\n",
    "    if match_obj:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def feature_num_capitals(string):\n",
    "    \"\"\"\n",
    "    Return the number of capital letters in the string.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for char in string:\n",
    "        if char.isupper():\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def feature_num_vowels(string):\n",
    "    \"\"\"\n",
    "    Return the number of vowels in the string.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for char in string:\n",
    "        if char.lower() in 'aeiou':\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def feature_num_consonants(string):\n",
    "    \"\"\"\n",
    "    Return the number of consonants in the string.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for char in string:\n",
    "        if char.isalpha() and char.lower() not in 'aeiou':\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def feature_num_characters(string):\n",
    "    \"\"\"\n",
    "    Return the number of characters in the string.\n",
    "    \"\"\"\n",
    "    return len(string)\n",
    "\n",
    "def feature_ascii_sum(string):\n",
    "    \"\"\"\n",
    "    Return the sum of ascii values of all the characters in the string.\n",
    "    \"\"\"\n",
    "    ascii_sum = 0\n",
    "    for char in string:\n",
    "        ascii_sum += ord(char)\n",
    "    return ascii_sum\n",
    "\n",
    "def feature_number_present(string):\n",
    "    \"\"\"\n",
    "    If the string has a digit, then return True.\n",
    "    \"\"\"\n",
    "    for char in string:\n",
    "        if char.isdigit():\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def feature_is_noun(string):\n",
    "    \"\"\"\n",
    "    If majority if the words in this string are tagged propernoun,\n",
    "    then return True.\n",
    "    nltk.help.upenn_tagset() tags that we are looking for\n",
    "    NNP: noun, proper, singular\n",
    "        Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
    "        Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
    "        Shannon A.K.C. Meltex Liverpool ...\n",
    "    NNPS: noun, proper, plural\n",
    "        Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
    "        Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
    "        Apache Apaches Apocrypha ...\n",
    "    \"\"\"\n",
    "    tokens = nltk.word_tokenize(string)\n",
    "    tagged_tokens = nltk.pos_tag(tokens)\n",
    "    for entry in tagged_tokens:\n",
    "        tag = entry[1]\n",
    "        if tag not in ['NNP', 'NNPS']:\n",
    "            return 0\n",
    "    return 1\n",
    "\n",
    "def feature_is_day_month(string):\n",
    "    \"\"\"\n",
    "    If one of the words in the string contains days of the week, or months return true\n",
    "    else return false.\n",
    "    \"\"\"\n",
    "    days_of_week = [\"monday\", \"tuesday\", \"wednesday\", \"thursday\", \"friday\",\n",
    "                    \"saturday\", \"sunday\"]\n",
    "    months = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "    words = string.split(\" \")\n",
    "    for word in words:\n",
    "        if word.lower() in days_of_week or word.lower() in months:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def feature_contains_stopwords(string):\n",
    "    \"\"\"\n",
    "    If one of the words in the string contains stopwords, return true\n",
    "    else return false.\n",
    "    \"\"\"\n",
    "    words = string.split(\" \")\n",
    "    for word in words:\n",
    "        if word.lower() in stopwords:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def feature_contains_city(string):\n",
    "    \"\"\"\n",
    "    If one of the words in the string is acity return true\n",
    "    else return false\n",
    "    \"\"\"\n",
    "    words = string.split(\" \")\n",
    "    for word in words:\n",
    "        if cities.get(word.lower()):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def feature_contains_Countries(string):\n",
    "    \"\"\"\n",
    "    If one of the words in the string is a Country return true\n",
    "    else return false\n",
    "    \"\"\"\n",
    "    words = string.split(\" \")\n",
    "    for word in words:\n",
    "        if Countries.get(word.lower()):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def feature_begins_sentence(string, content):\n",
    "    \"\"\"\n",
    "    If the first word occurs first in the sentence, the return true\n",
    "    else return false\n",
    "    \"\"\"\n",
    "    first_word = string.strip(\" \").split(\" \")[0]\n",
    "    assert(first_word)\n",
    "    match_obj = re.search( r\"\\. \" + first_word, content)\n",
    "    if match_obj:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def feature_contains_sports(string):\n",
    "    \"\"\"\n",
    "    This feature is to identify common sports terms. It will return true if\n",
    "    it is in one of these words\n",
    "    \"\"\"\n",
    "    terms = ['city', 'football', 'league', 'arsenal', 'united', 'premier',\n",
    "            'england', 'poland', 'champion', 'club', 'park', 'fc', 'director',\n",
    "            'manager', 'people', 'aston', 'villa', 'brom', 'referee', 'defend',\n",
    "            'midfield', 'win', 'anfield', 'devils', 'conference', 'olympic',\n",
    "            'international', 'canada', 'tel', 'france', 'derby', 'world', \n",
    "            'player', 'milan', 'sport', 'fifa', 'uefa']\n",
    "    \n",
    "    for var in terms:\n",
    "        if var in string.lower():\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def feature_is_noun_v2(string):\n",
    "    \"\"\"\n",
    "    Checks if a string is a noun using the context based dictionary\n",
    "    \"\"\"\n",
    "    tokens = nltk.word_tokenize(string.lower())\n",
    "    count = 0\n",
    "    for token in tokens:\n",
    "        pos_tag = global_pos_tag_vectors.get(token)\n",
    "        if pos_tag == None:\n",
    "            return 1\n",
    "        if pos_tag[0] >= pos_tag[1]:\n",
    "            count += 1\n",
    "    if count > len(tokens)/2:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def feature_is_verb_v2(string):\n",
    "    \"\"\"\n",
    "    Checks if a string is a verb using the context based dictionary\n",
    "    \"\"\"\n",
    "    tokens = nltk.word_tokenize(string.lower())\n",
    "    count = 0\n",
    "    for token in tokens:\n",
    "        pos_tag = global_pos_tag_vectors.get(token)\n",
    "        if pos_tag == None:\n",
    "            return 0\n",
    "        if pos_tag[0] < pos_tag[1]:\n",
    "            count += 1\n",
    "    if count > len(tokens)/2:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "# {word: [noun_hits, verb_hits]}\n",
    "global_pos_tag_vectors = defaultdict(lambda: [0, 0])\n",
    "\n",
    "def get_pos_tags(text):\n",
    "    \"\"\"\n",
    "        this gets a pos tag list on the untouched text,\n",
    "        so that nltk can use context to better predict\n",
    "        pos tags.\n",
    "        since a single word may be tagged differently in\n",
    "        different contexts, we remember each instance in \n",
    "        a global dictionary and then take a popular\n",
    "        vote to decide the pos tag.\n",
    "    \"\"\"\n",
    "\n",
    "    # nltk.tokenize breaks when it faces stuff like Â£120m\n",
    "    text = unicode(text, errors='ignore')\n",
    "    words = nltk.word_tokenize(text)\n",
    "    pos_tagged_words = nltk.pos_tag(words)\n",
    "    for word, pos_tag in pos_tagged_words:\n",
    "        if pos_tag in ['RB', 'RBR', 'RBS', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WRB']:\n",
    "            global_pos_tag_vectors[word.lower()][1] += 1\n",
    "        elif pos_tag in ['NNP', 'NNPS']:\n",
    "            global_pos_tag_vectors[word.lower()][0] += 1\n",
    "\n",
    "\n",
    "def get_feature_vectors(files):\n",
    "    data = []\n",
    "    read_cities()\n",
    "    read_countries()\n",
    "    count_names = 0\n",
    "    for filename in files:\n",
    "\n",
    "        # Read the whole marked file\n",
    "        with open('../Tagged_Dataset/' + filename) as f:\n",
    "            marked_contents = f.read()\n",
    "\n",
    "        # Extract all the full names that are tagged in the file\n",
    "        full_names = re.findall(r'<name>(.*?)</name>', marked_contents)\n",
    "        \n",
    "        # Extract all first names that tagged in the file\n",
    "        first_names = re.findall(r'<fname>(.*?)</fname>', marked_contents)\n",
    "        \n",
    "        # Extract all the last names that are tagged in the file\n",
    "        last_names = re.findall(r'<lname>(.*?)</lname>', marked_contents)\n",
    "\n",
    "        for name in full_names:\n",
    "            name_parts = name.split(' ')\n",
    "            first_names.append(name_parts[0])\n",
    "            last_names.append(name_parts[-1])\n",
    "            if len(name_parts) == 3:\n",
    "                last_names.append(\" \".join(name_parts[1:]))\n",
    "\n",
    "        file_names = set(full_names) | set(first_names) | set(last_names)\n",
    "        count_names = count_names + len(file_names)\n",
    "        \n",
    "        # Read the file from the original dataset\n",
    "        with open('../Original_Dataset/' + filename) as f:\n",
    "            original_contents = f.read()\n",
    "\n",
    "        # get pos tags on the untouched data\n",
    "        get_pos_tags(original_contents)\n",
    "        \n",
    "        # Extract all the words and do any filters or parsing before generating\n",
    "        # training set\n",
    "        words = re.split(' |\\n', original_contents)\n",
    "        filtered_words = filter(words_filter, words)\n",
    "        parsed_words = [parse_words(var) for var in filtered_words]\n",
    "\n",
    "        # Add words of length one into training set\n",
    "        training_set = []\n",
    "        for i in xrange(len(parsed_words)):\n",
    "            training_set.append(parsed_words[i])\n",
    "\n",
    "        # Add words of length two into training set\n",
    "        for i in xrange(len(parsed_words)-1):\n",
    "            training_set.append(parsed_words[i] + \" \" + parsed_words[i+1])\n",
    "\n",
    "        # Add words of length three into training set\n",
    "        for i in xrange(len(parsed_words)-2):\n",
    "            training_set.append(parsed_words[i] + \" \" + parsed_words[i+1] + \" \"\n",
    "                                + parsed_words[i+2])\n",
    "\n",
    "        filtered_training_set = filter(filter_training_set, training_set)\n",
    "\n",
    "        # Construct feature vectors for the data\n",
    "        for string in filtered_training_set:\n",
    "            feature1 = feature_possessive_form(string, original_contents)\n",
    "            feature2 = feature_num_capitals(string)\n",
    "            feature3 = feature_num_vowels(string)\n",
    "            feature4 = feature_num_consonants(string)\n",
    "            feature5 = feature_num_characters(string)\n",
    "            feature6 = feature_ascii_sum(string)\n",
    "            feature7 = feature_number_present(string)\n",
    "            feature8 = feature_is_noun(string)\n",
    "            feature9 = feature_is_day_month(string)\n",
    "            feature10 = feature_contains_stopwords(string)\n",
    "            feature11 = feature_contains_city(string)\n",
    "            feature12 = feature_begins_sentence(string, original_contents)\n",
    "            feature13 = feature_contains_sports(string)\n",
    "            feature14 = feature_is_noun_v2(string)\n",
    "            feature15 = feature_is_verb_v2(string)\n",
    "            feature16 = feature_contains_Countries(string)\n",
    "            data.append((string, label(string, file_names),\n",
    "                         feature1, feature2, feature3, feature4,\n",
    "                         feature5, feature6, feature7, feature8,\n",
    "                         feature9, feature10, feature11, feature12,\n",
    "                         feature13, feature14, feature15, feature16\n",
    "                        ))\n",
    "    print \"Length of data with features: \" + str(len(data))\n",
    "    print \"Number of names marked up: \" +str(count_names)\n",
    "    return data\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # Randomly split the 300 files into Set I (Development Set) and Set J (Test Set)\n",
    "    input_files = [ str(i).zfill(3) + '.txt' for i in xrange(1, 301) ]\n",
    "    \n",
    "    # Using the constant seed so that we don't mix up Set I and J in subsequent iterations\n",
    "    seed = 4\n",
    "    random.Random(seed).shuffle(input_files)\n",
    "    dev_set = input_files[:200]\n",
    "    test_set = input_files[200:]\n",
    "    assert(set(dev_set).union(set(test_set)) == set(input_files))\n",
    "    print \"Length of Dev set: \" + str(len(dev_set))\n",
    "    print \"Length of Test set:\" + str(len(test_set))\n",
    "    \n",
    "    # Generate feature vector for dev and test set\n",
    "    print \"Dev Set :\"\n",
    "    training_data = get_feature_vectors(dev_set)\n",
    "    print \"Test Set :\"\n",
    "    test_data = get_feature_vectors(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required packages and defining all functions needed to do the training\n",
    "\n",
    "import json\n",
    "import sys\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Function to perform training with Decision Tree - giniIndex.\n",
    "def train_using_gini(X_train, y_train):\n",
    "    # Creating the classifier object\n",
    "    clf_gini = DecisionTreeClassifier(criterion=\"gini\", random_state=100)\n",
    "\n",
    "    # Performing training\n",
    "    clf_gini.fit(X_train, y_train)\n",
    "    return clf_gini\n",
    "\n",
    "# Function to perform training with giniIndex.\n",
    "def train_using_logistic_regression(X_train, y_train):\n",
    "    # Creating the classifier object\n",
    "    lr_model = LogisticRegression(fit_intercept=True)\n",
    "    \n",
    "    # Performing training\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    return lr_model\n",
    "\n",
    "# Function to perform training with svm LinearSVC.\n",
    "def train_using_svm_SVC(X_train, y_train):\n",
    "    # Creating the classifier object\n",
    "    svm_model = svm.SVC(C=5)\n",
    "    \n",
    "    # Performing training\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    return svm_model\n",
    "\n",
    "# Function to perform training with Decision Tree - entropy.\n",
    "def train_using_entropy(X_train, y_train):\n",
    "    # Decision tree with entropy\n",
    "    clf_entropy = DecisionTreeClassifier(criterion=\"entropy\", random_state=100)\n",
    "\n",
    "    # Performing training\n",
    "    clf_entropy.fit(X_train, y_train)\n",
    "    return clf_entropy\n",
    "\n",
    "# Function to perform training random forest\n",
    "def train_using_random_forest(X_train, y_train):\n",
    "    # Creating the classifier object\n",
    "    rf_model = RandomForestClassifier(n_estimators = 1000, random_state = 100)\n",
    "    \n",
    "    # Performing training\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    return rf_model\n",
    "\n",
    "# Function to perform training using Gaussian Naive Bayes\n",
    "def train_using_gaussian_nb(X_train, y_train):\n",
    "    # Creating the classifier object\n",
    "    gaussian_nb_model = GaussianNB()\n",
    "    \n",
    "    # Performing training\n",
    "    gaussian_nb_model.fit(X_train, y_train)\n",
    "    return gaussian_nb_model\n",
    "    \n",
    "# Function to make predictions\n",
    "def prediction(X_test, clf_object):\n",
    "    y_pred = clf_object.predict(X_test)\n",
    "    return y_pred\n",
    "\n",
    "# Define custom function to verify P and R\n",
    "def cal_P_R(y_test, y_pred):\n",
    "    pos_test = np.sum(y_test == 1)\n",
    "    neg_test = np.sum(y_test == 0)\n",
    "\n",
    "    TP = np.sum(np.logical_and(y_pred == 1, y_test == 1))\n",
    "\n",
    "    # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n",
    "    TN = np.sum(np.logical_and(y_pred == 0, y_test == 0))\n",
    "\n",
    "    # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n",
    "    FP = np.sum(np.logical_and(y_pred == 1, y_test == 0))\n",
    "\n",
    "    # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n",
    "    FN = np.sum(np.logical_and(y_pred == 0, y_test == 1))\n",
    "    \n",
    "    P = (TP * 1.0) / (TP + FP)\n",
    "    R = (TP * 1.0) / (TP + FN)\n",
    "\n",
    "    print(\"P : \", P)\n",
    "    print(\"R : \", R)\n",
    "    print(\"TP : \", TP)\n",
    "    print(\"FP : \", FP)\n",
    "    print(\"TN : \", TN)\n",
    "    print(\"FN : \", FN)\n",
    "\n",
    "    \n",
    "# Function to calculate accuracy\n",
    "def cal_accuracy(y_test, y_pred):\n",
    "    print(\"Confusion Matrix: \",\n",
    "          confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    print(\"Accuracy : \",\n",
    "          accuracy_score(y_test, y_pred) * 100)\n",
    "\n",
    "    print(\"Report : \",\n",
    "          classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nhariharan/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/nhariharan/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Using Gini Index:\n",
      "('Confusion Matrix: ', array([[15612,   212],\n",
      "       [  205,  1346]]))\n",
      "('Accuracy : ', 97.6)\n",
      "('Report : ', u'              precision    recall  f1-score   support\\n\\n           0       0.99      0.99      0.99     15824\\n           1       0.86      0.87      0.87      1551\\n\\n   micro avg       0.98      0.98      0.98     17375\\n   macro avg       0.93      0.93      0.93     17375\\nweighted avg       0.98      0.98      0.98     17375\\n')\n",
      "('P : ', 0.8639281129653402)\n",
      "('R : ', 0.8678272082527402)\n",
      "('TP : ', 1346)\n",
      "('FP : ', 212)\n",
      "('TN : ', 15612)\n",
      "('FN : ', 205)\n",
      "Results Using Entropy:\n",
      "('Confusion Matrix: ', array([[15603,   221],\n",
      "       [  212,  1339]]))\n",
      "('Accuracy : ', 97.50791366906475)\n",
      "('Report : ', u'              precision    recall  f1-score   support\\n\\n           0       0.99      0.99      0.99     15824\\n           1       0.86      0.86      0.86      1551\\n\\n   micro avg       0.98      0.98      0.98     17375\\n   macro avg       0.92      0.92      0.92     17375\\nweighted avg       0.98      0.98      0.98     17375\\n')\n",
      "('P : ', 0.8583333333333333)\n",
      "('R : ', 0.8633139909735654)\n",
      "('TP : ', 1339)\n",
      "('FP : ', 221)\n",
      "('TN : ', 15603)\n",
      "('FN : ', 212)\n",
      "Results Using Logistic Regression:\n",
      "('Confusion Matrix: ', array([[15564,   260],\n",
      "       [  825,   726]]))\n",
      "('Accuracy : ', 93.75539568345323)\n",
      "('Report : ', u'              precision    recall  f1-score   support\\n\\n           0       0.95      0.98      0.97     15824\\n           1       0.74      0.47      0.57      1551\\n\\n   micro avg       0.94      0.94      0.94     17375\\n   macro avg       0.84      0.73      0.77     17375\\nweighted avg       0.93      0.94      0.93     17375\\n')\n",
      "('P : ', 0.7363083164300203)\n",
      "('R : ', 0.46808510638297873)\n",
      "('TP : ', 726)\n",
      "('FP : ', 260)\n",
      "('TN : ', 15564)\n",
      "('FN : ', 825)\n",
      "Results Using SVM:\n",
      "('Confusion Matrix: ', array([[15529,   295],\n",
      "       [  287,  1264]]))\n",
      "('Accuracy : ', 96.65035971223021)\n",
      "('Report : ', u'              precision    recall  f1-score   support\\n\\n           0       0.98      0.98      0.98     15824\\n           1       0.81      0.81      0.81      1551\\n\\n   micro avg       0.97      0.97      0.97     17375\\n   macro avg       0.90      0.90      0.90     17375\\nweighted avg       0.97      0.97      0.97     17375\\n')\n",
      "('P : ', 0.8107761385503528)\n",
      "('R : ', 0.8149580915538363)\n",
      "('TP : ', 1264)\n",
      "('FP : ', 295)\n",
      "('TN : ', 15529)\n",
      "('FN : ', 287)\n",
      "Results Using Random Forests:\n",
      "('Confusion Matrix: ', array([[15647,   177],\n",
      "       [  195,  1356]]))\n",
      "('Accuracy : ', 97.85899280575539)\n",
      "('Report : ', u'              precision    recall  f1-score   support\\n\\n           0       0.99      0.99      0.99     15824\\n           1       0.88      0.87      0.88      1551\\n\\n   micro avg       0.98      0.98      0.98     17375\\n   macro avg       0.94      0.93      0.93     17375\\nweighted avg       0.98      0.98      0.98     17375\\n')\n",
      "('P : ', 0.8845401174168297)\n",
      "('R : ', 0.874274661508704)\n",
      "('TP : ', 1356)\n",
      "('FP : ', 177)\n",
      "('TN : ', 15647)\n",
      "('FN : ', 195)\n",
      "Results Using Gaussian NB:\n",
      "('Confusion Matrix: ', array([[13484,  2340],\n",
      "       [   21,  1530]]))\n",
      "('Accuracy : ', 86.41151079136691)\n",
      "('Report : ', u'              precision    recall  f1-score   support\\n\\n           0       1.00      0.85      0.92     15824\\n           1       0.40      0.99      0.56      1551\\n\\n   micro avg       0.86      0.86      0.86     17375\\n   macro avg       0.70      0.92      0.74     17375\\nweighted avg       0.94      0.86      0.89     17375\\n')\n",
      "('P : ', 0.3953488372093023)\n",
      "('R : ', 0.9864603481624759)\n",
      "('TP : ', 1530)\n",
      "('FP : ', 2340)\n",
      "('TN : ', 13484)\n",
      "('FN : ', 21)\n"
     ]
    }
   ],
   "source": [
    "# First use the training set and train your model\n",
    "df_train = pd.DataFrame(training_data)\n",
    "df_train_original = df_train.copy()\n",
    "\n",
    "# Seperate labels\n",
    "train_labels = df_train.iloc[:,1]\n",
    "\n",
    "# Seperate train\n",
    "df_train = df_train.iloc[:,2:]\n",
    "\n",
    "# Split the dev set into train-test\n",
    "df_train, df_test, train_labels, test_labels = train_test_split(\n",
    "        df_train,train_labels, test_size=0.3, random_state=100)\n",
    "\n",
    "# Train the models using the split\n",
    "clf_gini = train_using_gini(df_train.values, train_labels)\n",
    "clf_entropy = train_using_entropy(df_train.values, train_labels)\n",
    "lr_model = train_using_logistic_regression(df_train.values, train_labels)\n",
    "svm_model = train_using_svm_SVC(df_train.values, train_labels)\n",
    "rf_model = train_using_random_forest(df_train.values, train_labels)\n",
    "gaussian_nb_model = train_using_gaussian_nb(df_train.values, train_labels)\n",
    "\n",
    "# Predict using the trained models in the dev set\n",
    "print(\"Results Using Gini Index:\")\n",
    "# Prediction using gini\n",
    "y_pred_gini = prediction(df_test.values, clf_gini)\n",
    "cal_accuracy(test_labels, y_pred_gini)\n",
    "cal_P_R(test_labels, y_pred_gini)\n",
    "\n",
    "print(\"Results Using Entropy:\")\n",
    "# Prediction using entropy\n",
    "y_pred_entropy = prediction(df_test.values, clf_entropy)\n",
    "cal_accuracy(test_labels, y_pred_entropy)\n",
    "cal_P_R(test_labels, y_pred_entropy)\n",
    "\n",
    "print(\"Results Using Logistic Regression:\")\n",
    "# Prediction using Logistic Regression\n",
    "y_pred_lr = prediction(df_test.values,lr_model)\n",
    "cal_accuracy(test_labels, y_pred_lr)\n",
    "cal_P_R(test_labels, y_pred_lr)\n",
    "\n",
    "print(\"Results Using SVM:\")\n",
    "# Prediction Using SVM\n",
    "y_pred_svm_SVC = prediction(df_test.values,svm_model)\n",
    "cal_accuracy(test_labels, y_pred_svm_SVC)\n",
    "cal_P_R(test_labels, y_pred_svm_SVC)\n",
    "\n",
    "print(\"Results Using Random Forests:\")\n",
    "# Prediction Using Random Forests\n",
    "y_pred_rf = prediction(df_test.values,rf_model)\n",
    "cal_accuracy(test_labels, y_pred_rf)\n",
    "cal_P_R(test_labels, y_pred_rf)\n",
    "\n",
    "print(\"Results Using Gaussian NB:\")\n",
    "# Prediction using Gaussian NB\n",
    "y_pred_gaussian_nb = prediction(df_test.values,gaussian_nb_model)\n",
    "cal_accuracy(test_labels, y_pred_gaussian_nb)\n",
    "cal_P_R(test_labels, y_pred_gaussian_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Printing Average Stats for: DecisionTreeClassifier\n",
      "Average Precision: 83.89179398960799\n",
      "Average Recall: 84.0877914951989\n",
      "F1 Score: 0.8398967839808569\n",
      "------------------------------\n",
      "Printing Average Stats for: DecisionTreeClassifier\n",
      "Average Precision: 84.66866867869915\n",
      "Average Recall: 84.33470507544581\n",
      "F1 Score: 0.845013569082505\n",
      "------------------------------\n",
      "Printing Average Stats for: LogisticRegression\n",
      "Average Precision: 72.86023894743282\n",
      "Average Recall: 47.59945130315501\n",
      "F1 Score: 0.5758121058588133\n",
      "------------------------------\n",
      "Printing Average Stats for: RandomForestClassifier\n",
      "Average Precision: 85.5730061199918\n",
      "Average Recall: 85.37722908093279\n",
      "F1 Score: 0.8547500549576418\n",
      "------------------------------\n",
      "Printing Average Stats for: GaussianNB\n",
      "Average Precision: 38.46737597361036\n",
      "Average Recall: 98.49108367626886\n",
      "F1 Score: 0.5532617051197529\n",
      "------------------------------\n",
      "Printing Average Stats for: SVC\n",
      "Average Precision: 80.57914134284374\n",
      "Average Recall: 76.84499314128944\n",
      "F1 Score: 0.7866777967829227\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Do a 3 fold Cross Validation across all the models to chose the best\n",
    "num_folds = 3\n",
    "models = [clf_gini, clf_entropy, lr_model, rf_model, gaussian_nb_model, svm_model]\n",
    "for classifier in models:\n",
    "    print \"-\" * 30 \n",
    "    print \"Printing Average Stats for: \" + str(type(classifier).__name__)\n",
    "    scores = cross_val_score(classifier, df_train, train_labels, cv=num_folds, scoring='precision')\n",
    "    P = np.mean(scores)\n",
    "    print \"Average Precision: \" + str(P * 100)\n",
    "    scores = cross_val_score(classifier, df_train, train_labels, cv=num_folds, scoring='recall')\n",
    "    R = np.mean(scores)\n",
    "    print \"Average Recall: \" + str(R * 100)\n",
    "    F1 = 2*(P*R)/(P+R)\n",
    "    print \"F1 Score: \"+ str(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since Random Forests are giving the best performance, we will pick this.\n",
    "# We are going to do some rule-based post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision before post processing: 88.4540117417\n",
      "Recall before post processing: 87.4274661509\n",
      "F1 Score before post processing 0.879377431907\n"
     ]
    }
   ],
   "source": [
    "# Calculate P,R and F1\n",
    "words = pd.DataFrame(df_train_original[0])\n",
    "words.columns = ['string']\n",
    "test_labels = pd.DataFrame(test_labels)\n",
    "test_labels.columns = ['actual_label']\n",
    "df_test.columns = [\n",
    "                   #'allCaps',\n",
    "                   'nextPoss', 'numCap', 'numVow' , 'numCons',\n",
    "                   'numChar', 'sumAscii', 'numberPres', 'isNoun',\n",
    "                   'isDay', 'isArticle', 'isCity', 'isStart', \n",
    "                  'containsSports', 'isNoun_v2', 'isVerb_v2', 'isCountry'\n",
    "                  ]\n",
    "\n",
    "debug_df = df_test.join(test_labels).join(words)\n",
    "debug_df['predicted_label'] = y_pred_rf\n",
    "\n",
    "# Compute statistics\n",
    "# false positives\n",
    "false_pos = debug_df[(debug_df['predicted_label'] == 1) & (debug_df['actual_label'] == 0)]\n",
    "# false negatives\n",
    "false_neg = debug_df[(debug_df['predicted_label'] == 0) & (debug_df['actual_label'] == 1)]\n",
    "# true positive\n",
    "true_pos = debug_df[(debug_df['predicted_label'] == 1) & (debug_df['actual_label'] == 1)]\n",
    "# true negative\n",
    "true_neg = debug_df[(debug_df['predicted_label'] == 0) & (debug_df['actual_label'] == 0)]\n",
    "\n",
    "# Precision\n",
    "print \"Precision before post processing: \" + str(100.0*true_pos.shape[0]/(true_pos.shape[0]+false_pos.shape[0]))\n",
    "\n",
    "# Recall\n",
    "print \"Recall before post processing: \" + str(100.0*true_pos.shape[0]/(true_pos.shape[0]+false_neg.shape[0]))\n",
    "\n",
    "#F1 Score\n",
    "P = true_pos.shape[0]*1.0/(true_pos.shape[0]+false_pos.shape[0])\n",
    "R = true_pos.shape[0]*1.0/(true_pos.shape[0]+false_neg.shape[0])\n",
    "F1 = 2*(P*R)/(P+R)\n",
    "print \"F1 Score before post processing \" + str(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision after post processing: 93.285198556\n",
      "Recall after post processing: 83.3010960671\n",
      "F1 Score before post processing 0.880108991826\n"
     ]
    }
   ],
   "source": [
    "# Our post processing rule is to ignore examples which have football related terms like \n",
    "# countries, football clubs,tournaments\n",
    "football_terms = []\n",
    "def read_football():\n",
    "    with open('football.csv') as f:\n",
    "        reader = csv.reader(f)\n",
    "\n",
    "        for row in reader:\n",
    "            football_terms.append(row[0].lower())\n",
    "\n",
    "# Read all the terms\n",
    "read_football()\n",
    "\n",
    "# Perform post processing step\n",
    "for index, row in debug_df.iterrows():\n",
    "    if row['predicted_label'] == 1:\n",
    "        for entry in football_terms:\n",
    "            if entry in row['string'].lower():\n",
    "                debug_df.loc[index, 'predicted_label'] = 0\n",
    "\n",
    "# Recompute all the statistics\n",
    "# false positives\n",
    "false_pos = debug_df[(debug_df['predicted_label'] == 1) & (debug_df['actual_label'] == 0)]\n",
    "# false negatives\n",
    "false_neg = debug_df[(debug_df['predicted_label'] == 0) & (debug_df['actual_label'] == 1)]\n",
    "# true positive\n",
    "true_pos = debug_df[(debug_df['predicted_label'] == 1) & (debug_df['actual_label'] == 1)]\n",
    "# true negative\n",
    "true_neg = debug_df[(debug_df['predicted_label'] == 0) & (debug_df['actual_label'] == 0)]\n",
    "\n",
    "# Precision\n",
    "print \"Precision after post processing: \" + str(100.0*true_pos.shape[0]/(true_pos.shape[0]+false_pos.shape[0]))\n",
    "\n",
    "# Recall\n",
    "print \"Recall after post processing: \" + str(100.0*true_pos.shape[0]/(true_pos.shape[0]+false_neg.shape[0]))\n",
    "\n",
    "#F1 Score\n",
    "P = true_pos.shape[0]*1.0/(true_pos.shape[0]+false_pos.shape[0])\n",
    "R = true_pos.shape[0]*1.0/(true_pos.shape[0]+false_neg.shape[0])\n",
    "F1 = 2*(P*R)/(P+R)\n",
    "print \"F1 Score before post processing \" + str(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the precision and recall are meeting the required assignment constriants we can apply it on the \n",
    "# test set which has been untouched so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Precision on Test Set J: 91.5966386555\n",
      "Final Recall on Test Set J: 81.8864774624\n",
      "F1 Score before post processing 0.864698104892\n"
     ]
    }
   ],
   "source": [
    "# Applying Model on Test Set J\n",
    "df_final_test = pd.DataFrame(test_data)\n",
    "df_final_test_original = df_final_test.copy()\n",
    "\n",
    "#S eperate labels\n",
    "test_labels = df_final_test.iloc[:,1]\n",
    "\n",
    "# Separate data\n",
    "df_final_test = df_final_test.iloc[:,2:]\n",
    "\n",
    "# Perform preficions\n",
    "y_final_pred_rf = prediction(df_final_test.values,rf_model)\n",
    "\n",
    "# Append the predicted values to original Data Frame to perform post processing\n",
    "words = pd.DataFrame(df_final_test_original[0])\n",
    "words.columns = ['string']\n",
    "test_labels = pd.DataFrame(test_labels)\n",
    "test_labels.columns = ['actual_label']\n",
    "df_final_test.columns = [\n",
    "                   'nextPoss', 'numCap', 'numVow' , 'numCons',\n",
    "                   'numChar', 'sumAscii', 'numberPres', 'isNoun',\n",
    "                   'isDay', 'isArticle', 'isCity', 'isStart', 'containsSports',\n",
    "                   'isNoun_v2', 'isVerb_v2', 'isCountry'\n",
    "                  ]\n",
    "\n",
    "debug_df_final = df_final_test.join(test_labels).join(words)\n",
    "\n",
    "debug_df_final['predicted_label'] = y_final_pred_rf\n",
    "\n",
    "# Perform the same post processing step as above  \n",
    "for index, row in debug_df_final.iterrows():\n",
    "    if row['predicted_label'] == 1:\n",
    "        for entry in football_terms:\n",
    "            if entry in row['string'].lower():\n",
    "                debug_df_final.loc[index, 'predicted_label'] = 0\n",
    "                \n",
    "# Compute Final statistics on Test Set J\n",
    "# false positives\n",
    "false_pos = debug_df_final[(debug_df_final['predicted_label'] == 1) & (debug_df_final['actual_label'] == 0)]\n",
    "# false negatives\n",
    "false_neg = debug_df_final[(debug_df_final['predicted_label'] == 0) & (debug_df_final['actual_label'] == 1)]\n",
    "# true positive\n",
    "true_pos = debug_df_final[(debug_df_final['predicted_label'] == 1) & (debug_df_final['actual_label'] == 1)]\n",
    "# true negative\n",
    "true_neg = debug_df_final[(debug_df_final['predicted_label'] == 0) & (debug_df_final['actual_label'] == 0)]\n",
    "\n",
    "# Precision\n",
    "print \"Final Precision on Test Set J: \" + str(100.0*true_pos.shape[0]/(true_pos.shape[0]+false_pos.shape[0]))\n",
    "\n",
    "# Recall\n",
    "print \"Final Recall on Test Set J: \" + str(100.0*true_pos.shape[0]/(true_pos.shape[0]+false_neg.shape[0]))\n",
    "\n",
    "#F1 Score\n",
    "P = true_pos.shape[0]*1.0/(true_pos.shape[0]+false_pos.shape[0])\n",
    "R = true_pos.shape[0]*1.0/(true_pos.shape[0]+false_neg.shape[0])\n",
    "F1 = 2*(P*R)/(P+R)\n",
    "print \"F1 Score before post processing \" + str(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These results meet the expected Project requirements of at least 90% Precision and 60% Recall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
